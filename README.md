## Resources
- https://medium.com/codex/building-a-powerful-image-search-engine-for-your-pictures-using-deep-learning-16d06df10385
- https://openai.com/index/clip/
- https://towardsdatascience.com/simple-implementation-of-openai-clip-model-a-tutorial-ace6ff01d9f2

## Ideas
- Based on CLIP, but instead of classifying captions based on images, we classify the images based on the captions. Then we can call it image - search with a text inquiry.

## TODO
- use the kaggle link , with the given set of pictures to train it.
- find out more about training it, like how exactly does CLIP works. I think it might be that you also have to put the text embeddings input by yourself and it is not autogenerated.
- look at the list of things you can do at the sticky notes.
- apply to 100 jobs.


# what I learned:
- when you load the images, it will burden your short term memory usage. whichis your memory.